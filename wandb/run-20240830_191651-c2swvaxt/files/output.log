/home/gauffrea/.local/lib/python3.8/site-packages/lightly/models/simsiam.py:65: Warning: The high-level building block SimSiam will be deprecated in version 1.3.0. Use low-level building blocks instead. See https://docs.lightly.ai/self-supervised-learning/lightly.models.html for more information
  warnings.warn(
Traceback (most recent call last):
  File "pretrain.py", line 106, in <module>
    main()
  File "pretrain.py", line 77, in main
    (x0, x1), _, _ = collate_fn([x])
  File "/home/gauffrea/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gauffrea/.local/lib/python3.8/site-packages/lightly/data/collate.py", line 73, in forward
    transforms = [
  File "/home/gauffrea/.local/lib/python3.8/site-packages/lightly/data/collate.py", line 74, in <listcomp>
    self.transform(batch[i % batch_size][0]).unsqueeze_(0)
  File "/home/gauffrea/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/gauffrea/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 135, in __call__
    return F.to_tensor(pic)
  File "/home/gauffrea/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py", line 137, in to_tensor
    raise TypeError(f"pic should be PIL Image or ndarray. Got {type(pic)}")
TypeError: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>
Traceback (most recent call last):
  File "pretrain.py", line 106, in <module>
    main()
  File "pretrain.py", line 77, in main
    (x0, x1), _, _ = collate_fn([x])
  File "/home/gauffrea/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/gauffrea/.local/lib/python3.8/site-packages/lightly/data/collate.py", line 73, in forward
    transforms = [
  File "/home/gauffrea/.local/lib/python3.8/site-packages/lightly/data/collate.py", line 74, in <listcomp>
    self.transform(batch[i % batch_size][0]).unsqueeze_(0)
  File "/home/gauffrea/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/gauffrea/.local/lib/python3.8/site-packages/torchvision/transforms/transforms.py", line 135, in __call__
    return F.to_tensor(pic)
  File "/home/gauffrea/.local/lib/python3.8/site-packages/torchvision/transforms/functional.py", line 137, in to_tensor
    raise TypeError(f"pic should be PIL Image or ndarray. Got {type(pic)}")
TypeError: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>